{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EebowCELhaAe"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This is a step by step approach to the Predictive Insights competition.\n",
        "\n",
        "Youth unemployment and under-employment is a major concern for any developing country, and serves as an important predictor of economic health and prosperity. Being able to predict, and understand,  which young people will find employment and which ones will require additional help,  helps promote evidence-based decision-making, supports economic empowerment, and allows young people to thrive in their chosen careers.\n",
        "\n",
        "The objective of this challenge is to build a machine learning model that predicts youth employment, based on data from labour market surveys in South Africa.\n",
        "\n",
        "This solution will help organisations like Predictive Insights achieve a baseline prediction of young peoples’ employment outcomes, allowing them to design and test interventions to help youth make a transition into the labour market or to improve their earnings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kq8DdN5hg0B"
      },
      "source": [
        "# The Data\n",
        "\n",
        "The data for this challenge comes from four rounds of a survey of youth in the South African labour market, conducted at 6-month intervals. The survey contains numerical, categorical and free-form text responses. You will also receive additional demographic information such as age and information about school level and results.\n",
        "\n",
        "Each person in the dataset was surveyed one year prior (the ‘baseline’ data) to the follow-up survey. We are interested in predicting whether a person is employed at the follow-up survey based on their labour market status and other characteristics during the baseline.\n",
        "\n",
        "The training set consists of one row or observation per individual - information collected at baseline plus only the target outcome (whether they were employed or not) one year later. The test set consists of the data collected at baseline without the target outcome.\n",
        "\n",
        "The objective of this challenge is to predict whether a young person will be employed, one year after the baseline survey, based on their demographic characteristics, previous and current labour market experience and education outcomes, and to deliver an easy-to-understand and insightful solution to the data team at Predictive Insights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KgP8EY6hl7f"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IdR0Fc9PQQa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf7bShHihryN"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "J6QcALw2PgjU",
        "outputId": "4c18a206-3d9d-411e-f44a-609bb72e326b"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"Train.csv\")\n",
        "df_test = pd.read_csv(\"Test.csv\")\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['Target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42fzS-FzX999",
        "outputId": "a6ed8c5a-f9ae-463c-c116-29d5b1868b9a"
      },
      "outputs": [],
      "source": [
        "df_train.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUwaMfhOh1_C"
      },
      "source": [
        "## Univariate Analysis\n",
        "\n",
        "Let's have a look at some of the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP2UHPh7h750"
      },
      "source": [
        "**sa_citizen**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9IH476kP6Dr",
        "outputId": "adb575f3-3e23-4695-b1c5-de3dfa54bea9"
      },
      "outputs": [],
      "source": [
        "df_train[\"Sa_citizen\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwkUm_8Vh-kX"
      },
      "source": [
        "The values where `sa_citizen` are 0 are very underrepresented. It could be a good idea to remove the rows where `sa_citizen` = 0 but that could lead to a loss of data. Alternatively, one could consider removing the column altogether.\n",
        "\n",
        "**geography**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqEUC8ITQJf0",
        "outputId": "48e8a76c-89d7-4b1f-e1c0-399d0c2ed1ca"
      },
      "outputs": [],
      "source": [
        "df_train[\"Geography\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49eTD7u6iZGO"
      },
      "source": [
        "From this, we see that candidates come from three geographical categories: Rural, Suburb, and Urban. The majority come from urban areas.\n",
        "\n",
        "**tenure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RBUvOVimQbJq",
        "outputId": "ac67c696-142f-4dc6-f6fb-cf89cbe16996"
      },
      "outputs": [],
      "source": [
        "# Generate a histogram of the tenure variable using matplotlib\n",
        "plt.hist(df_train[\"Tenure\"])\n",
        "plt.xlabel(\"Tenure\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram of Tenure\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALcMChFFihCo"
      },
      "source": [
        "This histogram indicates that `tenure` has a skewed distribution, with a concentration of values towards the lower end and the presence of outliers.\n",
        "\n",
        "Next, we will look at the distribution of the `birthyear` variable.\n",
        "\n",
        "**birthyear**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qT8W8TMiixjp",
        "outputId": "ad1ceaca-14d2-43d1-a942-44391c01a018"
      },
      "outputs": [],
      "source": [
        "# Generate a boxplot of the birthyear variable using matplotlib\n",
        "\n",
        "plt.boxplot(df_train['Birthyear'])\n",
        "plt.title(\"Boxplot of Birth Year\")\n",
        "plt.xlabel(\"Birth Year\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHG2nXCYjB7L"
      },
      "source": [
        "The presence of many points below the first quartile suggests a left-skewed skewed distribution, with many outliers on the lower end.\n",
        "To get more details, we can use the `pandas.DataFrame.describe()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjt2zzlfj0mB",
        "outputId": "0b2c2782-7efc-4bdd-c6b0-053ceabbefb8"
      },
      "outputs": [],
      "source": [
        "#  get the key statistics of `birthyear` using pandas.DataFrame.describe()\n",
        "df_train['Birthyear'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD7G2xlXkGwY"
      },
      "source": [
        "From this, we see that most candidates were born between 1995 and 2000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKXYuubLQ9Va"
      },
      "source": [
        "## Bivariate Analysis\n",
        "\n",
        "Now, let us look at the relationships between a few variables and the target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JI6OGwhfQegH",
        "outputId": "327db0f8-c694-4343-ac80-9eba9a330ddc"
      },
      "outputs": [],
      "source": [
        "sns.kdeplot(data=df_train, x=\"Birthyear\", hue=\"Target\", fill=True, alpha=0.5)\n",
        "plt.xlabel(\"Birth Year\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Histogram of Birth Year by Target\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1TmgisRkm6g"
      },
      "source": [
        "The ages of candidates with a positive outcome and those with a negative outcome seem to follow a similar distribution.\n",
        "\n",
        "We will now look at the percentage of candidates with a positive outcome in each province."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2GLIV17RNRy"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of positive income for each province\n",
        "\n",
        "df_province = df_train.groupby('Province').agg(percentage=('Target', 'mean')).reset_index()\n",
        "df_province[\"percentage\"] = df_province[\"percentage\"] * 100\n",
        "df_province = df_province.sort_values('percentage', ascending=False).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "F3VUwq8bRrP1",
        "outputId": "604485b9-1cde-4473-b5a4-3e9daa885cc5"
      },
      "outputs": [],
      "source": [
        "# Generate a bar plot for the 'percentage' positive income for each province\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_province, x='Province', y='percentage')\n",
        "plt.xlabel('Province')\n",
        "plt.ylabel('Percentage of Positive Outcome')\n",
        "plt.title('Percentage of Positive Outcome by Province')\n",
        "\n",
        "for index, row in df_province.sort_values('percentage', ascending=False).iterrows():\n",
        "  plt.text(row.name, row.percentage, f\"{round(row.percentage, 1)}%\", ha='center', va='bottom')\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hKRDfZGk2az"
      },
      "source": [
        "In the training data, candidates from the Western Cape are the most likely to get a positive outcome, while those from the North West province are least likely.\n",
        "\n",
        "What about the `geography` variable?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyUJde5sTd2P"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of positive income for each `geography`\n",
        "\n",
        "df_geography = df_train.groupby('Geography').agg(percentage=('Target', 'mean')).reset_index()\n",
        "df_geography[\"percentage\"] = df_geography[\"percentage\"] * 100\n",
        "df_geography = df_geography.sort_values('percentage', ascending=False).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "8-HpNkbPWQsy",
        "outputId": "7d9accb4-ad5e-4eee-a937-5945965dadd4"
      },
      "outputs": [],
      "source": [
        "# Generate a bar plot for the 'percentage' positive income for each `geography`\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=df_geography, x='Geography', y='percentage')\n",
        "plt.xlabel('Geography')\n",
        "plt.ylabel('Percentage of Positive Outcome')\n",
        "plt.title('Percentage of Positive Outcome by Geography')\n",
        "\n",
        "# Add labels to the bars\n",
        "for index, row in df_geography.iterrows():\n",
        "    plt.text(row.name, row.percentage, f\"{round(row.percentage, 1)}%\", ha='center', va='bottom')\n",
        "\n",
        "# Rotate x-axis labels\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC0dzNhAk7Lr"
      },
      "source": [
        "We see that people from \"Urban\" areas are most likely to get a positive outcome.\n",
        "\n",
        "In terms if gender, we see below that males in the data set are more likely to get a job after one year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US_spNsQWicJ"
      },
      "outputs": [],
      "source": [
        "df_female = df_train.groupby('Female').agg(percentage=('Target', 'mean')).reset_index()\n",
        "df_female[\"percentage\"] = df_female[\"percentage\"] * 100\n",
        "df_female = df_female.sort_values('percentage', ascending=False).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "zv8Fr5IxXNNc",
        "outputId": "160d43e0-9550-40ac-b114-6d5648719757"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_female, x='Female', y='percentage')\n",
        "plt.xlabel('Status')\n",
        "plt.ylabel('Percentage of Positive Outcome')\n",
        "plt.title('Percentage of Positive Outcome by Gender')\n",
        "\n",
        "# Add labels to the bars\n",
        "for index, row in df_female.iterrows():\n",
        "    plt.text(row.name, row.percentage, f\"{round(row.percentage, 1)}%\", ha='center', va='bottom')\n",
        "\n",
        "# Rotate x-axis labels\n",
        "plt.xticks(rotation=90, ha='center')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1axxWYLYoJr"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Feature engineering is the process of transforming raw data into meaningful features that may improve the performance of machine learning models. It involves selecting, creating, and transforming variables to capture relevant information and enhance the predictive power of the model.\n",
        "\n",
        "Let's extract the year of the survey then use it to calculate the age of each participant at the time of the survey."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOQevCTbXh6f",
        "outputId": "4728f011-52ed-41cd-98a2-9f7d11ac7791"
      },
      "outputs": [],
      "source": [
        "df_train['Year_survey'] = pd.to_datetime(df_train['Survey_date']).dt.year\n",
        "df_train['Age_survey'] = df_train['Year_survey'] - df_train['Birthyear']\n",
        "df_train['Age_survey'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjwhL7SVl4qm"
      },
      "source": [
        "Next, we create a variable that indicates the number of subjects where the participants have obtained 70% or more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU1o9Ls0l6mH",
        "outputId": "79abde26-c342-4069-f663-818284821db7"
      },
      "outputs": [],
      "source": [
        "df_train['Subjects_over_70'] = df_train.apply(lambda row: row.str.contains(\"80 - 100 %|70 - 79 %\").sum(), axis=1)\n",
        "df_train['Subjects_over_70'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHdT8INDuXPH"
      },
      "source": [
        "Feel free to explore these newly created variables and decide whether you'd like to discard them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGzBF_OuZ_q"
      },
      "source": [
        "## Dummy variables\n",
        "\n",
        "In this section, we convert our categorical variables into dummy variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-pOpgD6Y8Jz",
        "outputId": "ae80d709-1770-4901-be97-04785a9585f0"
      },
      "outputs": [],
      "source": [
        "# Create a list of categorical variables\n",
        "selected_vars = [\"Round\", \"Status\", \"Geography\", \"Province\",\n",
        "                                              \"Schoolquintile\", \"Math\", \"Mathlit\", \"Additional_lang\", \"Home_lang\", \"Science\"]\n",
        "# Remove variables we will not use\n",
        "df_train_dummy = df_train.drop([\"Person_id\", \"Survey_date\"], axis = 1)\n",
        "\n",
        "# Convert character variables to dummy variables\n",
        "df_train_dummy = pd.get_dummies(df_train_dummy, columns=selected_vars, drop_first=True, dummy_na=True)\n",
        "df_train_dummy.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Fd1gsTvMXR"
      },
      "source": [
        "# Data cleaning\n",
        "\n",
        "## Cleaning column names\n",
        "\n",
        "The dummification process created some messy column names. Here, we're trying to clean those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC-pn7CFbJ7x",
        "outputId": "ebf80d7b-2911-47f2-bba0-780740ee4a9c"
      },
      "outputs": [],
      "source": [
        "# Clean column names\n",
        "df_train_dummy.columns = df_train_dummy.columns.str.replace(' ', '_')  # Replace spaces with underscores\n",
        "df_train_dummy.columns = df_train_dummy.columns.str.replace('[^\\w\\s]', '', regex=True)  # Remove special characters\n",
        "df_train_dummy.columns = df_train_dummy.columns.str.replace('_+', '_', regex=True)  # Replace consecutive underscores with a single underscore\n",
        "df_train_dummy.columns = df_train_dummy.columns.str.rstrip('_')  # Remove trailing underscores at the end\n",
        "df_train_dummy.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyOtZGyiy0Pp"
      },
      "source": [
        "## Dealing with missing values\n",
        "\n",
        "We will use a simplified method for replacing missing values: replacing them with zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFVel-Bry1mN"
      },
      "outputs": [],
      "source": [
        "df_train_dummy = df_train_dummy.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHzxrldgwVlg"
      },
      "source": [
        "# Logistic Regression Modeling\n",
        "\n",
        "Logistic Regression is a statistical modeling technique used to predict binary outcomes or probabilities. It is commonly used when the dependent variable (target variable) is categorical and has two possible outcomes, such as yes/no, success/failure, or 0/1.\n",
        "\n",
        "To perform logistic regression with 10-fold cross-validation using scikit-learn, you can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkLFXJyixj8A"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save to csv file\n",
        "df_train_dummy.to_csv(\"clean_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX90WKzpx2t7",
        "outputId": "67505f77-b0aa-43bd-ee00-09cd758af32e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Separate the features and target variables\n",
        "X = df_train_dummy.drop('Target', axis=1)\n",
        "y = df_train_dummy['Target']\n",
        "\n",
        "# X.shape, y.shape\n",
        "\n",
        "# Set up logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Set up cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and calculate ROC AUC\n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN5sysJoSFO1",
        "outputId": "31b492ed-5f74-4d6a-973c-b7b69809a234"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print the mean ROC AUC score across folds\n",
        "print('Mean ROC AUC:', scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF5yW2ZSzwMJ"
      },
      "source": [
        "# Predict on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "kzflxT96zqcf",
        "outputId": "eeb54a6e-d1b4-435d-84ac-540d8fd75ee3"
      },
      "outputs": [],
      "source": [
        "# Test set preview\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr6-nUQcz3xU"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "We need to make sure the test data undergoes the same pre-processing steps as the training data did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5lRp9gbzyNn",
        "outputId": "514e24d7-7b05-4411-cf51-02aef70756f3"
      },
      "outputs": [],
      "source": [
        "# Create \"year_survey\" column then\n",
        "# Create \"age_survey\" column\n",
        "df_test['Year_survey'] = pd.to_datetime(df_test['Survey_date']).dt.year\n",
        "df_test['Age_survey'] = df_test['Year_survey'] - df_test['Birthyear']\n",
        "df_test['Age_survey'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJ9zllz0J-I",
        "outputId": "93e7658e-5304-4d21-fa36-afc47fdcc574"
      },
      "outputs": [],
      "source": [
        "df_test['Subjects_over_70'] = df_test.apply(lambda row: row.str.contains(\"80 - 100 %|70 - 79 %\").sum(), axis=1)\n",
        "df_test['Subjects_over_70'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8X6yzOw5hR2",
        "outputId": "9c37e007-d015-4aa5-ab76-e8d014f2ca45"
      },
      "outputs": [],
      "source": [
        "# Remove variables we will not use\n",
        "df_test_dummy = df_test.drop([\"Person_id\", \"Survey_date\"], axis = 1)\n",
        "\n",
        "# Convert character variables to dummy variables\n",
        "df_test_dummy = pd.get_dummies(df_test_dummy, columns=selected_vars, drop_first=True, dummy_na=True)\n",
        "\n",
        "# Clean column names\n",
        "df_test_dummy.columns = df_test_dummy.columns.str.replace(' ', '_')  # Replace spaces with underscores\n",
        "df_test_dummy.columns = df_test_dummy.columns.str.replace('[^\\w\\s]', '', regex=True)  # Remove special characters\n",
        "df_test_dummy.columns = df_test_dummy.columns.str.replace('_+', '_', regex=True)  # Replace consecutive underscores with a single underscore\n",
        "df_test_dummy.columns = df_test_dummy.columns.str.rstrip('_')  # Remove trailing underscores at the end\n",
        "df_test_dummy.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "REQexoZb56iE",
        "outputId": "27a8771b-e79c-44c1-ddda-c09e52106020"
      },
      "outputs": [],
      "source": [
        "# Dealing with missing values\n",
        "df_test_dummy = df_test_dummy.fillna(0)\n",
        "df_test_dummy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "320F1mRD6M3j"
      },
      "source": [
        "Now, let's predict!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "v9pd8oMn6LwJ",
        "outputId": "af8d2c08-759c-420d-c65f-25ed3212eabb"
      },
      "outputs": [],
      "source": [
        "# Fit the model on training set\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEiPvvoF6HeK",
        "outputId": "30602ff1-0369-439a-9fd9-7acf23e9b79c"
      },
      "outputs": [],
      "source": [
        "# Test on test set\n",
        "\n",
        "predictions = model.predict(df_test_dummy)\n",
        "print(predictions[:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVLCi9VO74Co"
      },
      "source": [
        "Now let's put our predictions in the format needed for submission.For every row in the dataset, submission files should contain 2 columns: ID and Target.\n",
        "Your submission file should look like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb5Kvnu27BFF",
        "outputId": "09690ecc-90a1-4c92-ce09-51d75406d8ef"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame df_submission with two columns \"ID\" and \"Target\"\n",
        "df_submission = pd.DataFrame({\"ID\": df_test[\"Person_id\"], \"Target\": predictions.astype(int)})\n",
        "print(df_submission.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcMomGWi9K6V"
      },
      "source": [
        "Save your submission as a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3phHXb08w74"
      },
      "outputs": [],
      "source": [
        "df_submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_q9bSfU9VpQ"
      },
      "source": [
        "Et voilà! You are now ready to submit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVTg7zRA9Y2A"
      },
      "source": [
        "Predictive Insights is a leader in behavioural science and artificial intelligence to improve business efficiency and profitability. Through a combination of data science, machine learning and behavioural insights, we help customers to accurately predict sales, staffing and stock levels. Our solution improves sales forecasting on average by 50 percent. We operate in Africa as well as Europe, Middle East and India in the restaurant, food processing, retail and financial service sectors.\n",
        "We are part of Alphawave, a specialised technology investment group supporting businesses seeking to do things that are complex to replicate.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
